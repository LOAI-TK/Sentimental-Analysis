# Sentimental analysis using HF-Bert and Gemini LLM

---

# Sentiment Analysis with BERT

This repository contains an exploratory workflow for performing sentiment analysis on text reviews using Hugging Face's BERT-based multilingual model. The project is structured as a Jupyter Notebook and demonstrates data cleaning, model inference, and insights generation.

⚠️ Note: The dataset used in this notebook comes from a private company. For confidentiality reasons, the raw data is not included in this repository. To replicate the workflow, you will need to supply your own dataset of text reviews.


# Project Phases

## 1. Data Cleaning

The notebook starts by cleaning and preparing the raw dataset of reviews. This phase includes:

- Removing HTML tags, special characters, and extra spaces.

- Normalizing text (lowercasing, stripping whitespace).

- Filtering out missing or irrelevant entries.

- Tokenizing text where appropriate.


## 2. Sentiment Analysis

In this phase, we apply Hugging Face's pretrained model nlptown/bert-base-multilingual-uncased-sentiment, which is capable of handling multiple languages. Steps include:

- Feeding cleaned reviews into the model.

- Generating sentiment predictions on a 3-class scale:

  1 = Negative

  2 = Neutral

  3 = Positive

- Handling batch predictions for efficiency.

- Storing predictions alongside the original data for further analysis.

## 3. Sentiment Insights Report

The final phase focuses on drawing insights from the model predictions:

- Aggregating sentiment scores across the dataset.

- Visualizing sentiment distribution with bar plots and histograms.

- Identifying common patterns, such as the proportion of negative vs. positive reviews.

- Comparing sentiment across different subgroups 

---

# Requirements

To run the notebook, install the following dependencies:

pip install torch transformers pandas matplotlib seaborn jupyter

# Usage

1. Clone the repository:

   git clone https://github.com/yourusername/your-repo.git

   cd your-repo

3. Install the requirements:

    pip install -r requirements.txt

    Launch Jupyter Notebook:

4. jupyter notebook

5. Open Exploratory+HF(NlpBertModel)+sentimentInsights.ipynb and run all cells sequentially.

---

# Results

- After running the notebook, you will obtain:

- A cleaned dataset of reviews ready for NLP tasks.

- Sentiment predictions (Negative, Neutral, Positive) for each review.

## Visual insights such as:

- Distribution of reviews across sentiment categories.

- Trends in customer opinions.

- Example charts showing how sentiment varies across subsets of data.

### Example Output

- Below are example plots generated by the notebook:

- Sentiment Distribution: A histogram showing the count of reviews by sentiment (Negative, Neutral, Positive).

- Category-Level Sentiment: If metadata is present, bar charts showing sentiment per category.

- Time Series Trends: Line charts of sentiment over time (if timestamp data is available).

---

# Model Reference

This project uses Hugging Face's BERT multilingual sentiment model. The model was adapted to output 3 sentiment classes (Negative, Neutral, Positive) instead of the original 5-star ratings.

---



---

# Gemini LLM Extension

This notebooks (Multilingual Customer Feedback Intelligence System.ipynb) and (GeminiVsHF-NLBBert.ipynb) continues the project by applying Google Gemini 2.5 Flash for multilingual customer feedback analysis. Unlike the Hugging Face workflow, this extension goes beyond sentiment and extracts structured insights:

- Final Sentiment (3-class): Negative, Neutral, Positive.

- Sarcasm Detection: Yes / No.

- Suggestions: Identifies whether the user proposes improvements, with type (Complaint, Feature Request, Operational Improvement, Other).

- Suggestion Text: A concise summary of the suggestion (if any).

- Emotion Classification: joy, frustration, anger, gratitude, disappointment, worry, etc.

- Tone Analysis: enthusiastic, professional, urgent, frustrated, disappointed, sarcastic, etc.

- Urgency Flag: Marks urgent feedback (based on language and tone cues).

- Impact Level: Low / Medium / High.

- Responsible Party: Suggests which team (delivery, customer service, billing, technical support, etc.) is responsible.

- Action Flag: Indicates if the feedback requires operational follow-up.

# API Setup

This notebook requires Google Gemini API keys. Add them to a .env file in the format:

    GEMINI_KEY_1=your_api_key_here

    GEMINI_KEY_2=your_api_key_here

    ... up to GEMINI_KEY_9 if you rotate keys

- The notebook will automatically rotate through keys when processing large datasets.

- Comparison with Hugging Face

- Both Hugging Face BERT and Gemini LLM provide 3-class sentiment classification.

- Gemini adds richer contextual insights (tone, emotion, sarcasm, urgency, etc.).

- This enables a more actionable intelligence system for businesses handling multilingual feedback.

# Results

- Structured JSON outputs per review with multiple dimensions (sentiment + metadata) and csv file.

- Enhanced dashboards possible by combining Hugging Face’s statistical reliability with Gemini’s contextual depth.

---

# Gemini vs Hugging Face Comparison

The notebook GeminiVsHF-NLBBert.ipynb directly compares both approaches side-by-side:

<p align="center">
<img width="682" height="521" alt="image" src="https://github.com/user-attachments/assets/59608aae-f4a3-4567-be74-98951c1d9249" />
</p>

This comparison allows users to decide whether to prioritize efficiency & reproducibility (HF) or context-rich analysis (Gemini) depending on their business needs.

---

# Contributing

Contributions are welcome! To contribute:

1. Fork the repository.

2. Create a new branch for your feature or bugfix.

3. Submit a pull request describing your changes.


---
